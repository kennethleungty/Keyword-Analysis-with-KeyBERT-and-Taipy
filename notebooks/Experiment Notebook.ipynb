{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0b9ef2b",
   "metadata": {},
   "source": [
    "# Keyword Analysis with KeyBERT and Taipy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be6d89b",
   "metadata": {},
   "source": [
    "## 01 - Extraction of arXiv Abstracts with API\n",
    "- https://github.com/lukasschwab/arxiv.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bdba88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arxiv\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from keybert import KeyBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65228909",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = arxiv.Search(\n",
    "            query = 'artificial intelligence',\n",
    "            max_results = 20,\n",
    "            sort_by = arxiv.SortCriterion.SubmittedDate,\n",
    "            sort_order = arxiv.SortOrder.Descending)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3875f5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for result in search.results():\n",
    "    print(result.entry_id)\n",
    "    print(result.published)\n",
    "    print(result.title)\n",
    "    print(result.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56de4024",
   "metadata": {},
   "source": [
    "___\n",
    "## 02 - SQLite Database Setup\n",
    "- https://www.digitalocean.com/community/tutorials/how-to-use-the-sqlite3-module-in-python-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073395dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connection = sqlite3.connect(\"../data/abstracts.db\")\n",
    "# cursor = connection.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5c1306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create new table in database\n",
    "# cursor.execute(\"CREATE TABLE IF NOT EXISTS abstracts_ai (id TEXT PRIMARY KEY, \\\n",
    "#                                                          title TEXT, \\\n",
    "#                                                          date_published TEXT, \\\n",
    "#                                                          abstract TEXT)\"\n",
    "#               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19e8dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Insert dummy row\n",
    "# cursor.execute(\"INSERT INTO abstracts_ai VALUES ('a1', \\\n",
    "#                                                  'test_title', \\\n",
    "#                                                  '2023-02-16 18:16:09+00:00', \\\n",
    "#                                                  'test abstract text')\"\n",
    "#               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c8badb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Fetch all rows\n",
    "# query = \"SELECT * FROM abstracts_ai\"\n",
    "# df = pd.read_sql_query(\"SELECT * FROM abstracts_ai\", connection)\n",
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa300ff3",
   "metadata": {},
   "source": [
    "___\n",
    "## 03 - Retrieve and Store arXiv AI Article Abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2667d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for result in search.results():\n",
    "#     entry_id = result.entry_id\n",
    "#     uid = entry_id.split('.')[-1]\n",
    "#     title = result.title\n",
    "#     date_published = result.published\n",
    "#     abstract = result.summary\n",
    "    \n",
    "#     query = 'INSERT OR REPLACE INTO abstracts_ai(id, title, date_published, abstract)' + \\\n",
    "#             ' VALUES(?, ?, ?, ?);'\n",
    "    \n",
    "#     fields = (uid, title, date_published, abstract)\n",
    "\n",
    "#     cursor.execute(query, fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21542f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fetch all rows\n",
    "# query = \"SELECT * FROM abstracts_ai\"\n",
    "# df = pd.read_sql_query(\"SELECT * FROM abstracts_ai\", connection)\n",
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ca1d43",
   "metadata": {},
   "source": [
    "## Alternative - Without SQLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396c6bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77d973c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in search.results():\n",
    "    entry_id = result.entry_id\n",
    "    uid = entry_id.split('.')[-1]\n",
    "    title = result.title\n",
    "    date_published = result.published\n",
    "    abstract = result.summary\n",
    "    \n",
    "    result_dict = {'uid': uid,\n",
    "                   'title': title,\n",
    "                   'date_published': date_published,\n",
    "                   'abstract': abstract\n",
    "                  }\n",
    "    \n",
    "    df_raw = df_raw.append(result_dict, ignore_index=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fae32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518c3528",
   "metadata": {},
   "source": [
    "___\n",
    "## 04 - DataFrame Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3808f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_raw.copy()\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c527aa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date_published'] = pd.to_datetime(df['date_published'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ed8235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty column to store keyword extraction output\n",
    "df['keywords_and_scores'] = ''\n",
    "\n",
    "# Create empty column to store top keywords\n",
    "df['keywords'] = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce627d6",
   "metadata": {},
   "source": [
    "___\n",
    "## 05 - Keyword Extraction with KeyBERT\n",
    "- https://github.com/MaartenGr/KeyBERT\n",
    "- https://maartengr.github.io/KeyBERT/guides/embeddings.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b85cef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Using 'all-MiniLM-L6-v2' given its speed and good quality\n",
    "# https://www.sbert.net/docs/pretrained_models.html#model-overview\n",
    "kw_model = KeyBERT(model='all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d28b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "stop_words = 'english'\n",
    "ngram_lower_bound = 1\n",
    "ngram_upper_bound = 2\n",
    "use_mmr = True\n",
    "diversity = 0.1\n",
    "use_maxsum=False\n",
    "nr_candidates = 20\n",
    "top_n = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7028f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in df.iterrows():\n",
    "    abstract_text = row['abstract']\n",
    "    kw_output = kw_model.extract_keywords(abstract_text, \n",
    "                                  keyphrase_ngram_range=(ngram_lower_bound, ngram_upper_bound), \n",
    "                                  stop_words=stop_words,\n",
    "                                  use_mmr=use_mmr, \n",
    "                                  use_maxsum=use_maxsum,\n",
    "                                  diversity=diversity,\n",
    "                                  top_n=top_n)\n",
    "    df.at[i, 'keywords_and_scores'] = kw_output\n",
    "    \n",
    "    # Obtain keyword from every keyword-score pair\n",
    "    top_kw = []\n",
    "    \n",
    "    for pair in kw_output:\n",
    "        top_kw.append(pair[0])\n",
    "        \n",
    "    df.at[i, 'keywords'] = top_kw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6592de",
   "metadata": {},
   "source": [
    "### Get value counts of keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b793b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_count = pd.DataFrame(pd.Series([x for item in df.keywords for x in item]).value_counts()).reset_index()\n",
    "keywords_count.columns = ['keyword', 'count']\n",
    "keywords_count.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keybert_taipy_venv",
   "language": "python",
   "name": "keybert_taipy_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
